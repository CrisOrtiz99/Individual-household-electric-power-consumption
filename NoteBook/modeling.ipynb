{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paquetes a ocupar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift, \n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df, \n",
    "                 label_columns=None):\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "    def split_to_inputs_labels(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    def plot(self, model=None, plot_col='Global_active_power', max_subplots=3):\n",
    "        inputs, labels = self.sample_batch\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        \n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "    \n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def compile_and_fit(model, window, patience=3, max_epochs=50):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                   patience=patience,\n",
    "                                   mode='min')\n",
    "    \n",
    "    model.compile(loss=MeanSquaredError(),\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=[MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(window.train,\n",
    "                       epochs=max_epochs,\n",
    "                       validation_data=window.val,\n",
    "                       callbacks=[early_stopping])\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definición de la ventana de datos\n",
    "column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "multi_window = DataWindow(input_width=24, label_width=24, shift=24, label_columns=['Global_active_power'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo de línea base\n",
    "class MultiStepLastBaseline(Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return tf.tile(inputs[:, -1:, :], [1, 24, 1])\n",
    "        return tf.tile(inputs[:, -1:, self.label_index:], [1, 24, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_last = MultiStepLastBaseline(label_index=column_indices['Global_active_power'])\n",
    "\n",
    "baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluación del modelo de línea base en el conjunto de validación y prueba\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "\n",
    "val_performance['Baseline - Last'] = baseline_last.evaluate(multi_window.val)\n",
    "performance['Baseline - Last'] = baseline_last.evaluate(multi_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y evaluación de otros modelos (Linear, Dense, LSTM, CNN, AR-LSTM)\n",
    "linear = Sequential([\n",
    "    Dense(1, kernel_initializer=tf.initializers.zeros)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(linear, multi_window)\n",
    "\n",
    "val_performance['Linear'] = linear.evaluate(multi_window.val)\n",
    "performance['Linear'] = linear.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "dense = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, kernel_initializer=tf.initializers.zeros),\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense, multi_window)\n",
    "\n",
    "val_performance['Dense'] = dense.evaluate(multi_window.val)\n",
    "performance['Dense'] = dense.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dense(1, kernel_initializer=tf.initializers.zeros),\n",
    "])\n",
    "\n",
    "history = compile_and_fit(lstm_model, multi_window)\n",
    "\n",
    "val_performance['LSTM'] = lstm_model.evaluate(multi_window.val)\n",
    "performance['LSTM'] = lstm_model.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(32, activation='relu', kernel_size=(KERNEL_WIDTH)),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(1, kernel_initializer=tf.initializers.zeros),\n",
    "])\n",
    "\n",
    "history = compile_and_fit(cnn_model, cnn_multi_window)\n",
    "\n",
    "val_performance['CNN'] = cnn_model.evaluate(cnn_multi_window.val)\n",
    "performance['CNN'] = cnn_model.evaluate(cnn_multi_window.test, verbose=0)\n",
    "\n",
    "AR_LSTM = AutoRegressive(units=32, out_steps=24)\n",
    "\n",
    "history = compile_and_fit(AR_LSTM, multi_window)\n",
    "\n",
    "val_performance['AR - LSTM'] = AR_LSTM.evaluate(multi_window.val)\n",
    "performance['AR - LSTM'] = AR_LSTM.evaluate(multi_window.test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
